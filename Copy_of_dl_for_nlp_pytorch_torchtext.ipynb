{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panf11/nlp_tutorial/blob/master/Copy_of_dl_for_nlp_pytorch_torchtext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VBL1CLLejqe"
      },
      "source": [
        "# Deep Learning For NLP with PyTorch and Torchtext\n",
        "\n",
        "This is the companion code for my article in medium. There will be no further explanation here, just pure code. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZxl4MYNejqi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torchtext.data import Field \n",
        "from torchtext.data import Dataset, Example\n",
        "from torchtext.data import BucketIterator\n",
        "from torchtext.vocab import FastText\n",
        "from torchtext.vocab import CharNGram\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amN49G5xejqj"
      },
      "outputs": [],
      "source": [
        "embedding = FastText('simple')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJjk5UrWejqk"
      },
      "outputs": [],
      "source": [
        "# embedding_charngram = CharNGram()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUaJ1Mahejqk",
        "outputId": "7cbd3120-afc4-46e6-a392-6d53be2cbe76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my name is Jack</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi I am Jack</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hello There!</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi I am cooking</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello are you there?</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>There is a bird there</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    text label\n",
              "0        my name is Jack     Y\n",
              "1           Hi I am Jack     Y\n",
              "2           Hello There!     Y\n",
              "3        Hi I am cooking     N\n",
              "4   Hello are you there?     N\n",
              "5  There is a bird there     N"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame([\n",
        "    ['my name is Jack', 'Y'],\n",
        "    ['Hi I am Jack', 'Y'],\n",
        "    ['Hello There!', 'Y'],\n",
        "    ['Hi I am cooking', 'N'],\n",
        "    ['Hello are you there?', 'N'],\n",
        "    ['There is a bird there', 'N'],\n",
        "], columns=['text', 'label'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIZkDt7Jejql"
      },
      "outputs": [],
      "source": [
        "text_field = Field(\n",
        "    sequential=True,\n",
        "    tokenize='basic_english', \n",
        "    fix_length=5,\n",
        "    lower=True\n",
        ")\n",
        "\n",
        "label_field = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "# sadly have to apply preprocess manually\n",
        "preprocessed_text = df['text'].apply(\n",
        "    lambda x: text_field.preprocess(x)\n",
        ")\n",
        "\n",
        "# load fastext simple embedding with 300d\n",
        "text_field.build_vocab(\n",
        "    preprocessed_text, \n",
        "    vectors='fasttext.simple.300d'\n",
        ")\n",
        "\n",
        "# get the vocab instance\n",
        "vocab = text_field.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psGC_c7bejqm",
        "outputId": "3f7982ca-c1c9-4ccc-b896-3a250d4236fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# known token, in my case print 12\n",
        "print(vocab['are'])\n",
        "# unknown token, will print 0\n",
        "print(vocab['crazy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q7spiHzejqn",
        "outputId": "97d7871f-d007-44c4-e6e5-b7e3b777d4c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['my name is Jack', 'Y']\n",
            "['Hi I am Jack', 'Y']\n",
            "['Hello There!', 'Y']\n",
            "['Hi I am cooking', 'N']\n",
            "['Hello are you there?', 'N']\n",
            "['There is a bird there', 'N']\n"
          ]
        }
      ],
      "source": [
        "for i, r in df.iterrows():\n",
        "    print(list(r.values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUQxx4t4ejqo"
      },
      "outputs": [],
      "source": [
        "# we still have to manually handle conversion from categorical to int\n",
        "ltoi = {l: i for i, l in enumerate(df['label'].unique())}\n",
        "df['label'] = df['label'].apply(lambda y: ltoi[y])\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) \n",
        "                for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeqbjVMmejqo"
      },
      "outputs": [],
      "source": [
        "train_dataset, test_dataset = DataFrameDataset(\n",
        "    df=df, \n",
        "    fields=(\n",
        "        ('text', text_field),\n",
        "        ('label', label_field)\n",
        "    )\n",
        ").split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7aCIt9Rejqp"
      },
      "outputs": [],
      "source": [
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), \n",
        "    batch_sizes=(2, 2),\n",
        "    sort=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTF4Xck_ejqp"
      },
      "outputs": [],
      "source": [
        "class ModelParam(object):\n",
        "    def __init__(self, param_dict: dict = dict()):\n",
        "        self.input_size = param_dict.get('input_size', 0)\n",
        "        self.vocab_size = param_dict.get('vocab_size')\n",
        "        self.embedding_dim = param_dict.get('embedding_dim', 300)\n",
        "        self.target_dim = param_dict.get('target_dim', 2)\n",
        "        \n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, model_param: ModelParam):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(\n",
        "            model_param.vocab_size, \n",
        "            model_param.embedding_dim\n",
        "        )\n",
        "        self.lin = nn.Linear(\n",
        "            model_param.input_size * model_param.embedding_dim, \n",
        "            model_param.target_dim\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.embedding(x).view(x.size()[0], -1)\n",
        "        features = F.relu(features)\n",
        "        features = self.lin(features)\n",
        "        return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC5UMxY-ejqq"
      },
      "outputs": [],
      "source": [
        "class MyModelWithPretrainedEmbedding(nn.Module):\n",
        "    def __init__(self, model_param: ModelParam, embedding):\n",
        "        super().__init__()\n",
        "        self.embedding = embedding\n",
        "        self.lin = nn.Linear(\n",
        "            model_param.input_size * model_param.embedding_dim, \n",
        "            model_param.target_dim\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.embedding[x].reshape(x.size()[0], -1)\n",
        "        features = F.relu(features)\n",
        "        features = self.lin(features)\n",
        "        return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EO6jVeCejqq",
        "outputId": "7b9f610a-b6c6-4c45-cdaa-08852d0a1631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss on epoch 0 : 0.439\n",
            "test loss on epoch 0: 5.784\n",
            "train loss on epoch 1 : 0.002\n",
            "test loss on epoch 1: 8.804\n",
            "train loss on epoch 2 : 0.000\n",
            "test loss on epoch 2: 11.002\n",
            "train loss on epoch 3 : 0.000\n",
            "test loss on epoch 3: 12.678\n",
            "train loss on epoch 4 : 0.000\n",
            "test loss on epoch 4: 13.999\n"
          ]
        }
      ],
      "source": [
        "model_param = ModelParam(\n",
        "    param_dict=dict(\n",
        "        vocab_size=len(text_field.vocab),\n",
        "        input_size=5\n",
        "    )\n",
        ")\n",
        "model = MyModel(model_param)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_losses = list()\n",
        "    for batch in train_iter:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        prediction = model(batch.text.T)\n",
        "        loss = loss_function(prediction, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_losses.append(loss.item())\n",
        "    print('train loss on epoch {} : {:.3f}'.format(epoch, np.mean(epoch_losses)))\n",
        "    \n",
        "    test_losses = list()\n",
        "    for batch in test_iter:\n",
        "        with torch.no_grad():\n",
        "            optimizer.zero_grad()\n",
        "            prediction = model(batch.text.T)\n",
        "            loss = loss_function(prediction, batch.label)\n",
        "            \n",
        "            test_losses.append(loss.item())\n",
        "    \n",
        "    print('test loss on epoch {}: {:.3f}'.format(epoch, np.mean(test_losses)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of dl-for-nlp-pytorch-torchtext.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}